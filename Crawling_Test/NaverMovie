# 네이버 개봉 예정작 정보 가져오기

from bs4 import BeautifulSoup
import requests as req
import pandas as pd
import re

def Result(result):
	df_w = pd.DataFrame(result)
	df_w.to_excel(excel_writer="네이버 개봉예정작.xlsx", sheet_name = f'전체내역', index = False, engine='xlsxwriter')

def WebCrawMain2(url):
	reqs = req.get(url)
	soup = BeautifulSoup(reqs.text, 'html.parser')
	Result = []
	movie = soup.select('dl.lst_dsc')
	for i in movie:
		# 개요 <a href="/movie/bi/mi/basic.naver?code=201352">킬링 데이트</a> 로 정보 가져옴
		title     = i.select_one('dt.tit a')
		linkCode  = title.attrs["href"].split("?code=")[1]
											
		# 영화 장르, 감독, 배우 등의 정보를 가져옴 (해당 정보는 info_txt1 > dd > link_txt 에 존재)
		data  = i.select("dl.info_txt1 dd")
		# 첫번째 dd 정보: 장르
		Cate  = ",".join(i.text for i in data[0].select("a"))
		
		regDate = re.compile("\d{4}.\d{2}.\d{2}")
		regDate2 = re.compile("\d{4}.\d{2}")
		date1 = regDate.findall(str(data[0]))
		date2 = regDate2.findall(str(data[0]))

		if not date1:
			Date = date2[0]
		else:
			Date = date1[0]

		# 두번째 dd 정보: 감독
		Direct= ",".join(i.text for i in data[1].select("a"))

		# 세번째 dd 정보: 배우 but 배우가 없는 경우도 있기에 
		if len(data) > 2:
			Actor = ",".join(i.text for i in data[2].select("a"))
		else:
			Actor = "No"

		reqs2 = req.get(f"https://movie.naver.com/movie/bi/mi/detail.naver?code={linkCode}")
		soup2 = BeautifulSoup(reqs2.text, 'html.parser')

		# 영화 배급사 경우 dl.agency_name > dd 에 위치 (탭, 띄어쓰기, 개행문자도 들어가 있음) -> 특히 제작사가 dd 까지만 해서 데이터가 있으므로 a는 넣으면 안됨
		movieDetail = soup2.select("dl.agency_name dd")

		Agency= ",".join(i.text for i in movieDetail)
		Agency = Agency.replace("\t","")
		Agency = Agency.replace("\n","")
		Agency = Agency.replace("\r","")
		# 추후 엑셀로 만들기 용이하기 위해 [{}, {}, {}] 리스트 안 딕셔너리 형태로 저장
		movieInfo = {
		 	"영화제목": title.text,
		    "링크코드": linkCode,
			"개봉일"  : Date,
		 	"영화장르": Cate,
		 	"영화감독": Direct,
		 	"영화배우": Actor,
			"제작/수입/배급사": Agency
		 }
		print(movieInfo)
		Result.append(movieInfo)
	return Result

if __name__ == "__main__":	
	url  = "https://movie.naver.com/movie/running/premovie.naver"
	Data = WebCrawMain2(url)
	Result(Data)
